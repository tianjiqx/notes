# 大数据系统-鉴赏

鉴赏系列：

回答一下几个问题：

- 使用场景

- 核心原理、架构
- 优、缺点，竞品比较





## 1. Hadoop

### 1.1 目标场景

hadoop是作为目前大数据生态的海量数据存储基础设施，hadoop的分布式文件系统HDFS，





1.3 优缺点

1.3.2 缺点

1.3.2.1 计算框架MRv1的缺点

- 扩展性问题，jobTacker同时具有资源管理和作业控制功能，导致成为瓶颈制约扩展性
- 可靠性，mastr/slave ，单点故障。
- 资源利用率低，槽位机制，map，reduce不共享
- 无法支持其他计算框架，内存计算，流计算，迭代计算，只用于磁盘的离线计算。





## 2.Spark

### 2.1 目标场景



### 2.2 基本原理

#### 2.2.1 执行流程

![](大数据系统鉴赏/Snipaste_2021-06-15_03-18-03.png)

具体运行流程如下：

1. SparkContext 向资源管理器注册并向资源管理器申请运行Executor

2. 资源管理器分配Executor，然后资源管理器启动Executor

3. Executor 发送心跳至资源管理器

4. SparkContext 构建DAG有向无环图

5. 将DAG分解成Stage（TaskSet）

6. 把Stage发送给TaskScheduler

7. Executor 向 SparkContext 申请 Task

8. TaskScheduler 将 Task 发送给 Executor 运行

9. 同时 SparkContext 将应用程序代码发放给 Executor

10. Task 在 Executor 上运行，运行完毕释放所有资源

Spark Application中可以因为不同的Action触发众多的job，一个Application中可以有很多的job，每个job是由一个或者多个Stage构成的，后面的Stage依赖于前面的Stage，也就是说只有前面依赖的Stage计算完毕后，后面的Stage才会运行。

Stage划分的依据就是宽依赖，像reduceByKey，groupByKey等算子，会导致宽依赖的产生。

#### 2.2.2 spark on yarn

![](大数据系统鉴赏/Snipaste_2021-06-15_03-43-40.png)

![](大数据系统鉴赏/Snipaste_2021-06-15_03-45-46.png)

application的spark-context在本机。



shuffle write：stage，task结果输出到本地文件系统。

shuffle read：stage读取依赖的stage的数据

本地读，远程读。（bar work）





### REF

- [Spark底层执行原理详细解析](https://mp.weixin.qq.com/s/qotI36Kx3nOINKHdOEf6nQ)

- Spark技术内幕 深入解析spark内核架构设计与实现原理-张安站



## 3.Yarn

### 3.1 场景

MR v1的改进版本，独立的资源管理框架，可以支持不同的计算框架，MR，Spark等。





### 3.2 Yarn原理

#### 3.2.1 基本架构

![](大数据系统鉴赏/Snipaste_2021-06-15_04-01-33.png)



#### 3.2.2 yarn工作流程

![](大数据系统鉴赏/Snipaste_2021-06-15_04-06-49.png)

1. 步 骤 1 用 户 向 YARN 中 提 交 应 用 程 序， 其 中 包 括 ApplicationMaster 程 序、 启 动ApplicationMaster 的命令、 用户程序等。
2. 步骤 2 ResourceManager 为 该 应 用程 序 分 配 第 一 个 Container， 并 与 对应 的 NodeManager 通信， 要求它在这个 Container 中启动应用程序的 ApplicationMaster。
3. 步 骤 3 ApplicationMaster 首 先 向 ResourceManager 注 册， 这 样 用 户 可 以 直 接 通 过
   ResourceManage 查看应用程序的运行状态， 然后它将为各个任务申请资源， 并监控它的运
   行状态， 直到运行结束， 即重复步骤 4~7。
4. 步骤 4 ApplicationMaster 采用轮询的方式通过 RPC 协议向 ResourceManager 申请和
   领取资源。
5. 步骤 5 一旦 ApplicationMaster 申请到资源后， 便与对应的 NodeManager 通信， 要求
   它启动任务。
6. 步骤 6 NodeManager 为任务设置好运行环境（包括环境变量、 JAR 包、 二进制程序
   等） 后， 将任务启动命令写到一个脚本中， 并通过运行该脚本启动任务。（与ArgoDBBAR的导入导出脚本，异曲同工）
7. 步骤 7 各个任务通过某个 RPC 协议向 ApplicationMaster 汇报自己的状态和进度， 以
   让 ApplicationMaster 随时掌握各个任务的运行状态， 从而可以在任务失败时重新启动任务。
   在应用程序运行过程中， 用户可随时通过 RPC 向 ApplicationMaster 查询应用程序的当
   前运行状态。
8. 步骤 8 应用程序运行完成后，ApplicationMaster 向 ResourceManager 注销并关闭自己。



#### 3.2.3 容错

app master 容错：RM 心跳检查，重启

container 容错：RM+AM处理

RM容错：HA



### 3.3 优缺点

### 3.3.1 相比MRv1优点

-  资源利用率提升。不同框架计算引擎，可以共用一套物理集群，运维成本降低。
- 数据共享，不同框架共用hdfs资源数据。
- 





### REF

- hadoop技术内幕：深入解析yarn架构设计与实现原理-董西成
- 





## 4.Delta Lake



## 5.HBase



## 6. Hive



## 7.Presto

Presto是一个分布式的采用**MPP架构**的查询引擎，本身并不存储数据，但是可以接入多种数据源，并且**支持跨数据源的级联查询**。Presto是一个OLAP的工具，擅长对海量数据进行复杂的分析；但是对于OLTP场景，并不是Presto所擅长，所以不要把Presto当做数据库来使用。

Presto是一个低延迟高并发的**内存计算引擎**。需要从其他数据源获取数据来进行运算分析，它可以连接多种数据源，包括Hive、RDBMS（Mysql、Oracle、Tidb等）、Kafka、MongoDB、Redis等。



![](大数据系统鉴赏/Snipaste_2021-06-15_02-11-54.png)

额外:为了支持多源，也使用classloader方式，支持不同的数据源client，依赖的不同版本的jar包



TODO：比较星环联邦计算方案

spark 批处理架构，sql，谓词等下推（dblink技术，jdbc），数据源（oracle，cdh，TD等）



和Apache HAWQ（MPP和批处理融合）差异？

支持的数据源。

## 8.Impala

Apache Impala是采**用MPP架构**的查询引擎，本身不存储任何数据，**直接使用内存进行计算**，兼顾数据仓库，具有实时，批处理，多并发等优点。

提供了类SQL（类Hsql）语法，在多用户场景下也能拥有较高的响应速度和吞吐量。它是由Java和C++实现的，Java提供的查询交互的接口和实现，C++实现了查询引擎部分。



Impala支持共享Hive Metastore，但没有再使用缓慢的 Hive+MapReduce 批处理，而是**通过使用与商用并行关系数据库中类似的分布式查询引擎**（由 Query Planner、Query Coordinator 和 Query Exec Engine 三部分组成），可以直接从 HDFS 或 HBase 中用 SELECT、JOIN 和统计函数查询数据，从而大大降低了延迟。

Impala经常搭配存储引擎Kudu一起提供服务，这么做最大的优势是查询比较快，并且支持数据的Update和Delete。

## 9.Elasticsearch



## 10.Clickhouse



## 11.Kafka



## 12.Flink



## 13.Pulsar



## 14.Kylin



