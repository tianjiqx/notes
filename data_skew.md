
## 数据倾斜解决方案

数据倾斜是指，数据的分布不均衡，不服从均匀分布，而是类似Zipf分布，导致hash等方式散列切分任务的不均衡，广泛存在与各个场景,，例如在大数据处理系统中，数据倾斜将导致长尾任务，在数据库中数据倾斜也导致hash join桶深很大，性能恶化,此外数据倾斜也导致数据库系统中不同值个数、中间结果集大小估计误差较大，本文档将介绍一些关于数据倾斜的解决方案。


### 数据库系统中数据倾斜的检测

- 利用统计信息

  数据库系统其实存在统计信息，记录了一些高频值信息，我们可以定义 $ \frac{T_{高频值行数}}{T_{低频值行数或总行数}} $ 作为倾斜比例，高频值比例越大，则倾斜比越大，超过一定阈值即可判断出现数据倾斜

- 数据实时采样

  在2016年的VLDB上有一篇论文《Flow-Join: Adaptive skew handling for distributed joins over high-speed networks》，介绍了一种新的处理数据倾斜的分布式连接方法Flow-Join，该连接方法是在连接过程中，根据已经处理的部分数据(1%)，构建代价极小的近似直方图的结构，根据key的频率，判断数据是否存在倾斜(全局是否倾斜的共识)。这样可以不需要统计信息，并且适应在统计信息不可用（经过过滤条件过滤后）、中间结果集是否存在数据倾斜。



### Flow join的方法

主要场景优化场景是**主外键连接**，倾斜key也是指外键上的key。处理示意图下图所示。

![Flow join](https://raw.githubusercontent.com/tianjiqx/picture/master/flow-join1.png)

  
- 探测阶段

  根据1%的数据，检查（右表）是否存在倾斜的key(随着处理，更新倾斜key)，spaceSving算法统计频数，收集各节点上左表的频数统计，然后合并，检查阈值

- 识别并交换

  存在时，将key（左表，右表的倾斜key）广播到所有的处理节点，构建hash桶，右表（探测表）的倾斜key保留在本地处理节点(避免网络开销)，进行处理，而非发送到根据key映射的处理节点集中进行处理。


细节：O(1)的频数记录（使用有序数组+hash table），RDMA，并行执行等细节，请参考论文.

扩展：**广义的Flow Join**，对于两表都存在倾斜key时，广播R、S表的倾斜key（且非S、R表倾斜key），对称片段复制SFR处理R、S相同的倾斜key。
- R、S中都不倾斜的情形，直接发送到目标服务器上处理
- R倾斜key满足阈值前，发送到目标服务器处理，满足之后插入到本地hash表
- 只在R上倾斜的key，满足阈值前在目标服务器上处理，满足之后由于S会广播发送到所有服务器，所以也能正确处理
- S倾斜key满足阈值前，发送到目标服务器处理，满足之后物化到本地，由于R的对应的元组没有还没广播
- 只在S上倾斜key，在满足阈值前在目标服务上处理，因为R上对应的元组会发送到目标服务器，满足阈值之后，等待R广播对应的倾斜key后连接，所以都能正确处理。
- R、S上都倾斜的key：
  - R上的都倾斜key，满足阈值前在目标服务器上处理，满足之后插入到本地hash表，注意不会广播到所有处理节点,产生错误的结果,最后通过SFR处理。
  - S上都倾斜key，满足阈值前在目标服务器上处理，满足之后物化到本地，最后通过SFR处理。

  
![Flow join](https://raw.githubusercontent.com/tianjiqx/picture/master/flow-join2.png)

注意：需要理解，在倾斜key未达到阈值前被认为是非倾斜的进行处理，在R、S都发现是倾斜key前，当作单边倾斜处理，R上的倾斜key插入本地的hash表，S上的倾斜key物化到本地，及时广播S上的R的倾斜key，交换完毕后，广播R上的S的倾斜key，最后用SFS处理R、S都倾斜的key。


R、S都倾斜key的连接方法，假设R和S上在每个服务上都右x和y行倾斜key，一种是广播小表，则导致传输$n(n-1)x$的传输数据量，很容易造成网络拥塞，另一个方法是将所有的数据集中在一台服务器上，则传输$(n-1)×(x+y)$的数据量，网络上的数据量减少了，但是单台服务器进行join的时间将极慢。

所谓的**对称分段复制SFR**,是指将服务器逻辑组织呈一个n1×n2的矩形(n1×n2=n,n为服务器的数量)，然后将R和S上的倾斜key分别同行同列之间进行广播，减少全域广播某一个小表R时导致的网络拥塞，同时也避免单点处理的时间瓶颈，而SFR的矩形n1，n2的比例根据R和S倾斜key元祖数的比例来确定，大致比例相等时n1=n2最好，而当比例相差极大的时候，原矩形退化成1×n,实际上变成了广播。SFR的传输的数据量为$n((n1-1)x+(n2-1)y)$。在最好的情况下，即n1=n2时，对比广播连接方式减少执行时间和网络拥塞的$\frac{\sqrt{n}+1}{2}$倍。


如下图所示，Server0将产生$R_{0,3,6} \biguplus S_{0,1,2}$,Server1将产生$R_{0,3,6}\biguplus  S_{3,4,5}$,Server1将产生$R_{0,3,6}\biguplus  S_{6,7,8}$综合起来，将产生结果$R_{0-8}\biguplus  S_{0-8}$。(注意，$\biguplus $代表join，mathjar不支持join符号，sadness)

![Flow join](https://raw.githubusercontent.com/tianjiqx/picture/master/flow-join3.png)


后记，所谓的SFR（1993年提出），其实只是计算机体系结构中并行处理技术中一个很基本的矩阵乘法分块并行处理的例子。

### 大数据处理系统如Spark中的解决方法


以下内容参考[美团点评技术团队](https://tech.meituan.com/)的相关文档。

- 使用Hive ETL预处理数据：对数据源的频繁处理，可考虑预处理数据，之后重用，避免Spark处理倾斜的数据
- 过滤少数导致倾斜的key：对于只存在少量key倾斜时，过滤掉然后，单独处理
- 提高shuffle操作的并行度：对于倾斜key较多时，提高task数，限定每个task处理的key的数量，可以减轻任务工作量的倾斜（实际效果有限）
- **两阶段聚合**（局部聚合+全局聚合）：该方法是预先给key添加一个随机前缀，或者值联合原值作为新key，将原始不均匀的key，变得均匀，之后对新key切分task，完成后，去除前缀或者值，恢复为原key再次聚合，如此能够将原始倾斜程度大大缓解，但是需要注意此方法仅限于reduce,聚合类操作，各个task处理不相关，对于**join类操作，无法使用该方法**。
- reduce join转为map join（数据广播）：此方法的思想时将小表广播到所有的处理节点，避免hash混洗，任务集中，限制条件是**小表与大表进行连接**。
- 采样倾斜key并分拆join操作： 利用**数据分治**的思想，预先采样，将一张表的倾斜key进行提取出来，随机增加前缀分成n份，使其均匀化然后单独处理，将另外一张表的对应的key提取出来然后膨胀n倍，分别与倾斜部分连接，而两表不倾斜的部分，正常join。此方法适用与一大表（事实表）存在**少量倾斜的key**，另一张大表(纬度表)对应key均匀的情形
- 使用随机前缀和扩容RDD进行join：该方法是前一个方法的通用方法，使用**空间换时间**的思想，在倾斜key多的时候，不单独处理了，直接全部添加随机前缀，然后将整个纬度表扩展n倍，加速执行，该方法的明显缺陷是内存消耗很大。

以上方法可以组合使用，解决执行过程的各个阶段的问题，最后总体执行时间得以加快。



### 待续...


### 参考


- Flow-Join: Adaptive skew handling for distributed joins over high-speed networks
- [Spark性能优化指南——高级篇](https://tech.meituan.com/spark_tuning_pro.html) 



