# 向量化执行

## 1. 概念

**Vectorized Execution** 向量化执行

- 最早使用在monetDB， 和商业版本VectorWise；Quickstep
- 与火山式迭代模型一样，矢量化使用基于**拉**的迭代，但是每次next调用都会获取一个元组块而不是一个元组，这会分摊迭代器调用开销
  - 解释执行
- 在实际的查询处理过程中，往往会在一个或多个具体类型（静态类型）列上执行原语操作（一批，按列执行），例如计算一个integer vector的hash值
- 使用code generation（代码生成）技术来解决静态类型带来的code explosion（代码爆炸）问题
  - 生成各种类型的计算原语，例如ADD (int , int)，ADD(int , long)



**Compiled / data-centric code generation  execution** 编译执行、代码生成

- 思想：减少需要执行的指令，让通用的代码变得专用
- （数据库中）HyPer开创，支持的系统Spark，Peloton，apache drill
- 每个关系运算符实现基于**推送**的接口（produce和consume）
  - produce和consume不是直接处理元组，而是为给定查询生成代码
  - 类似，深度遍历查询计划树，在第一次访问时调用produce，在处理完所有子项后在上次访问时使用consume
- 生成的代码具体化用于查询的特定数据类型，并将非阻塞关系运算符管道中的所有运算符融合到单个（可能是嵌套的）循环中。
  - 然后将该生成的代码编译为有效的机器代码（例如，LLVM的IR）
    - 预先编译，将大量虚函数调用，非确定性寻址，多个operator合并编译成一个可执行机器code，指令可pipeline执行
      - 代价：编译开销 ms级
    - LLVM 提供IR，最终被后端编译成优化过的机器码





## 2. 基本原理

主要参考论文：

[Everything You Always Wanted to Know About Compiled and Vectorized Queries But Were Afraid to Ask](https://www.vldb.org/pvldb/vol11/p2209-kersten.pdf)



### 2.1 Vectorized Execution

向量化执行的主要原理是在按列组织的数据上批量执行。

通过批量操作，分摊数据库解释执行的开销。

**hash join**

- `probeHash_` 表达式为每个joinkey列，调用一个原语来对joinkey列进行散列，并将散列写入输出vector
  - 原语操作，对单列，多列需要多次调用，取交集？
- 连接函数，使用该vector从hashtable中生成候选位置
- 然后，`compareKeys_`检查所有候选位置是否相等
  - `compareKeys_` 是build side的joinkey？



**SIMD指令集**

> AVX512 指令集，每个周期可以执行两个 512 位 SIMD 操作。
>
> 使用 AVX-512 每个周期可以处理 32 个 32 位的值，而标量代码限制为每个周期 4 个值。效率提升8倍。



**SIMD对选择和hash探测的影响:**

- 选择
  - 实现：
    - 比较指令生成一个掩码，将其传递给压缩存储 (COMPRESSSTORE) 指令，跨 SIMD 通道工作，并将掩码选择的位置写入内存
  - 基准测试，8k的int32，恰好装进L1的数据缓存，小于常量的过滤，性能提升8.4倍
    - 与simd指令自身效率符合预期，完美利用了simd
  - 但是在具有多个过滤条件时（Q6），只获得了1.4倍的加速
    - ![](向量化执行-笔记图片/Snipaste_2021-10-19_23-12-58.png)
    - 原因：
      - 选择向量导致的稀疏数据加载
        - 除第一个选择原语外，后续的选择原语都需要从不连续的内存中搜集，导致整体性能不到8倍而是接近3倍（40%的选择性下）
      - 步幅变化导致的缓存未命中
        - 由于大部分时间都在等待内存数据，导致 SIMD 指令作用下降
        - ![](向量化执行-笔记图片/Snipaste_2021-10-19_23-21-08.png)
          - 可以看出随着选择率变大，l1-miss 的时钟周期数降低
          - l1 cache miss 占总的时钟周期很高
          - 完全扫描时，simd比标量计算使用的时钟周期少的优势，更明显。在50%选择率时，基本一致了，更低反而略有下降。

- 散列连接探测
  - 应用simd
    - 计算hash值
      - Murmur2，由算术运算组成
    - 在hashTable中查找
      - 使用收集、压缩存储和掩码应用于对哈希表的查找
      - ![](向量化执行-笔记图片/Snipaste_2021-10-19_23-28-40.png)
        - hash可以提升2.3x
        - 收集1.1x
        - 总体join提升1.4x
        - 而在tpc-h测试集上提升几乎为0（10%）
          - 随着工作集的增长，执行成本主要由内存延迟决定， **SIMD仅在所有数据都适合缓存时才有用**
          - （也即，类似于计算引擎再快，而被底层扫描文件block了，整体性能还是没有多少提升）



- 单独的编译器的自动向量化，也几乎不会产生任何收益



TODO：自适应查询执行



### 2.2 Compiled Execution

编译执行的主要原理是为SQL查询生成低级代码，将查询管道的所有相邻非阻塞运算符融合到一个紧密循环中。



**hash join**

将其中一个输入的所有元组放进hash表中，多个join条件时，多列生成组合key。

探测时，对另一张表，同样使用该方法，生成key。



**并行性**

- VectorWise使用Exchange 算子，查询处理运算符（如聚合和连接）不感知并行性
  - 7.2X 提升
- HyPer 使用morsel-driven 并行性，连接和聚合使用共享哈希表，并明确感知并行性
  -  能够实现更好的局部性、负载平衡以及可扩展性
  - 11.7x 提升



- Tectorwise实现morsel-driven：
  - 为每个worker创建执行算子和资源，并且算子可以创建公式状态的实例，以进行通信
    - 如共享hash table
  - pipeline breaking 算子，强制执行子任务的全局顺序。hash table构建完毕后才能探测

![](向量化执行-笔记图片/Snipaste_2021-10-25_23-34-18.png)

实验结果：

- Q1,Q3,Q9 加速比，提升8，9倍
- Q6受内存带宽限制
- Q18受写入带宽限制
- 超线程（10*2）后，加速比更加接近
- 总结：扩展性都很好，都可以充分支持并行化





TODO：基于push 、 pull的编译



### 2.3 Vectorized vs Compiled 

> Tectorwise 执行的指令明显更多（高达 2.4 倍）并且通常有更多的 L1 数据缓存未命中（高达 3.3 倍

Vectorized Execution将所有操作分解为简单的步骤，并且必须在这些步骤之间实现中间结果，从而产生额外的指令和缓存访问。

Compiled Execution通常可以将中间结果保存在 CPU 寄存器中，从而以更少的指令执行相同的操作



> 对于较大的数据（和哈希表）大小，Tectorwise 的连接优势增加了 40%
>
> 向量化在隐藏缓存未命中延迟方面更好，Tectorwise 的哈希表探测代码只是一个简单的循环，只执行哈希表探测，因此 CPU 的乱序引擎可以提前推测并生成许多未完成的负载，减少CPU 停止等待内存的周期数。（hash计算，hash表无法完全装载进cpu cache，产生缓存未命中，因此，对于重连接的查询，向量化表现更好）
>
> Typer 的代码有更复杂的循环，每个循环可以包含用于扫描、选择、哈希表探测、聚合等的代码，每个 CPU 的乱序窗口会更快地被复杂的循环填满，因此它们产生的未完成负载更少。



>  Tectorwise 通常执行更多每周期指令 (IPC)，比Typer高出40%, 但是在tpc-h q1上性能慢了Typer 74%，因为执行的指令是2倍。IPC反映了Tectorwise 的提供了cpu利用率，但是并不一定会提高性能。



OLAP性能方面

- **计算**：编译执行更擅长，将数据保存在寄存器中，需要执行的指令更少
  - 编译代码，一次性处理所有列的谓词，而向量化一批只能处理一列的谓词，多列的谓词时需要多次处理，所以指令更多。
- **并行数据访问**：向量化执行在生成并行缓存未命中方面稍好一些，在访问大型哈希表以进行聚合或连接的内存绑定查询中具有一些优势
- **SIMD**：收益很小，因为大多数操作都受内存访问成本的支配
- **并行化**：矢量化引擎和基于编译的引擎都可以在多核 CPU 上很好地扩展
- **硬件平台**：不占主导地位
  - arm，intel

其他

- 编译
  - OLTP，可以创建快速存储过程
  - 语言支持，可以无缝集成用不同语言编写的代码
- 向量化
  - 编译时间，原语是预编译的
  - profiling分析，运行时可以归属于原语
  - 适应性，执行原语可以mid-fligh（飞行途中？）交换



**简单总结：**

向量化和编译执行，两种执行引擎性能差异一般不大，基于编译的引擎在计算量大的查询中具有优势，而向量化引擎更擅长隐藏缓存未命中延迟，例如hash连接。



TODO：

编译执行与向量化执行是正交的，可以融合在一起。例如Impala。



编译和矢量化的结合，能够获得更好的结果，编译应该与按块的查询项结合。

“循环编译”（将查询的核心编译成一个循环，在元组上进行迭代）技术可能不如普通矢量化，因为

-  (i) SIMD 对齐
- (ii) 避免分支错误预测的能力
-  (iii)并行内存访问

这时应该将编译拆分为多个循环，实现中间向量化结果。





## 3.原型系统/论文

### 3.1 MonetDB/X100

**动机**：

数据库系统在现代CPU上的IPC（每周期指令数）很低的原因。

研究内容：

- 基于tpc-h测试集分析，分析查询处理器的设计准则
- 基于准则设计了MonetDB/X100
  - 基于向量化的执行，tpc-h 100G提升了1-2个数量级（X100）

**Introduction**

- 现代CPU支持并行计算的能力
  - 流水线（指令并行）
  - 超标量（硬件资源复制）
- 数据库系统在现代CPU上的IPC（每周期指令数）很低
  - 10% 的真正有效工作研究
    - 消耗在其他组件（事务，加锁等）功能完成
  - 执行本身的低效，未能利用CPU的并行性
    - 架构本身，迭代器模型Volcano原因，解释执行开销
  - 具体测试商业DBMS   IPC为0.7，而科学计算（矩阵乘法）可以达到 2.
- MonetDB/MIL 系统在算子之间对全列数据做物化，受到内存带宽的严重限制, 导致 CPU 效率急剧下降. 
  - 全列数据量超过CPU cache大小，因此受限与内存带宽
  - MonetDB/X100 实际是对 tuple-at-a-time 和 column-at-a-time 的折中，减少Volcano迭代额外开销，又利用CPU cache。

- CPU MHz性能提升原理
  - 流水线技术，将 CPU 指令的工作划分为更多阶段，允许叠加更多的晶体管数量
    - 但是近来已经无法提升再细分下去了（2004年，Pentium4 已经有 31 个流水线级）
    - 单核瓶颈，转向多核
  - 流水线的缺点
    -  如果一条指令需要前一条指令的结果，则不能在它之后立即将其推入流水线，而必须等到第一条指令通过流水线
    - 分支预测失败问题（if-else），丢弃管道所有治疗，重新开始，导致浪费 数十个CPU时钟周期

- CPU 执行的所有指令中约有 30% 是内存加载和存储
  - 因此只有数据在CPU的缓存时，CPU才能以其最大吞吐量运行，否则只能空等
    - 访问内存 50ns  = 180 cycle  in 3.6 Ghz

**TPC-H分析**

Q1:

- 选择条件过滤很差, 对于 6M 的 lineitem 行, 过滤后还有 5.9M.

- Group by 分组很少(4组)， 可以使用 hash table可以完全放在在 CPU cache 中



### 3.2 Hyper

[Efficiently Compiling Efficient Query Plans for Modern Hardware](https://15721.courses.cs.cmu.edu/spring2019/papers/19-compilation/p539-neumann.pdf)



### 3.3 Vectorization vs. Compilation

[Vectorization vs. Compilation in Query Execution](https://15721.courses.cs.cmu.edu/spring2016/papers/p5-sompolski.pdf)



**Introduction**

- 数据库声明式查询语言的灵活性，通常使用解释执行引擎，遵循迭代器模型Volcano，基于pull遍历算子树。



## 4.实现

支持 向量化执行的系统：

- 数据库OLTP
  - polardb-x
  - cockroachdb
  - tidb
- OLAP
  - impala
  - spark
  - StarRocks





## REF

论文：

- [MonetDB/X100: Hyper-Pipelining Query Execution](http://cidrdb.org/cidr2005/papers/P19.pdf)
  - [论文翻译、笔记-知乎-卡比卡比](https://zhuanlan.zhihu.com/p/430203013)
- [Vectorization vs. Compilation in Query Execution](https://15721.courses.cs.cmu.edu/spring2016/papers/p5-sompolski.pdf)
- [Everything You Always Wanted to Know About Compiled and Vectorized Queries But Were Afraid to Ask](https://www.vldb.org/pvldb/vol11/p2209-kersten.pdf)
- [Efficiently Compiling Efficient Query Plans for Modern Hardware](https://15721.courses.cs.cmu.edu/spring2019/papers/19-compilation/p539-neumann.pdf)
  - [论文阅读-知乎-platoneko](https://zhuanlan.zhihu.com/p/430211068)
- Materialization Strategies in a Column-Oriented DBMS
- Rethinking SIMD Vectorization for In-Memory Databases
- Breaking the Memory Wall in MonetDB
- Relaxed Operator Fusion for In-Memory Databases: Making Compilation, Vectorization, and Prefetching Work Together At Last



扩展材料：

- [十分钟成为 Contributor 系列 | 助力 TiDB 表达式计算性能提升 10 倍](https://pingcap.com/zh/blog/10mins-become-contributor-of-tidb-20190916)
  - 为函数实现`vectorized()` 和 `vecEvalXType()` 按chunk进行处理，并输出结果，支持向量化执行表达式（表达式中所有的函数都执行向量化(2+6)*3，即MultiplyInt， PlusInt都需要实现向量化方法）
- [十分钟成为 Contributor 系列 | TiDB 向量化表达式活动第二弹](https://zhuanlan.zhihu.com/p/85553472) 
- [[面向guard编程系列] 2. 一元guard的使用： 一个避免静态代码爆炸的C++ idiom，用于OLAP向量化执行引擎的开发](https://zhuanlan.zhihu.com/p/338241036) 
  - C++ 代码生成，向量化执行的代码，guard 审计合法的类型
- [数据库计算引擎的优化技术：向量化执行与代码生成](https://zhuanlan.zhihu.com/p/100933389) 
- [每次都需要解释大量指令？使用 PolarDB-X 向量化引擎](https://zhuanlan.zhihu.com/p/354572485)
  - 2021.10.20 开源：[ApsaraDB](https://github.com/ApsaraDB)/**[galaxysql](https://github.com/ApsaraDB/galaxysql)**
  - （与Pandora-matrix实现类似）
  - batch ，vector，selection数据结构
    - selection数组用于延迟物化，避免每次过滤后，直接在原vector上操作，重新拷贝数据
  - 向量化原语
  - 短路求值
    - case when
- [PolarDB-X 向量化引擎的类型绑定与代码生成](https://zhuanlan.zhihu.com/p/357520668) 
  - 上下文构建
    - 确定表达式的输入输出类型，分配原语
    - 为原语分配向量
    - 原语代码生成
  - 处理
    - 表达式绑定
      - 表达式树前序遍历，函数签名，实例化向量化原语
    - 静态类型系统
      - 自顶向下的表达式类型推导
    - 代码模板
- [cockroachdb:how-we-built-a-vectorized-execution-engine](https://www.cockroachlabs.com/blog/how-we-built-a-vectorized-execution-engine/)
  - 底层存储是kv，非列式，OLTP数据库
  - 在磁盘读取行后，转换为批的列存数据格式，再输入到向量化执行引擎
  - 使用代码生成来减轻向量化执行引擎的维护负担
    - 向量化执行后，分析性能瓶颈在类型转换，类型断言开销上，因此改进是通过代码生成具体类型（不手写重复代码，使用模板，go不支持泛型），提升2倍。（代码量膨胀。rust零成本抽象呢，编译后，知道使用具体的类型，某些方面可能更容易达到高性能，而无需代码生成？宏？）
    - 批处理+模板化代码，比原来提升5.5
    - 进一步优化，多层循环，更改循环顺序，影响
      - 分支预测
      - 流水线
    - 最终提升20倍。基准测试cpu时间提升70倍，tpch测试提升4倍（磁盘时间占比最大，降低了整体的加速比）
  - (该文章包含golang pprof 分析过程)
- [slides: Vectorized Query Execution in Apache Spark at Facebook](https://databricks.com/session/vectorized-query-execution-in-apache-spark-at-facebook) 2019
  - vector at a time + whole stage CodeGen
  - 提升8x的读10M 行单列的表
  - 提升3.5x的读写10M 行单列的表
- [查询编译综述](https://zhuanlan.zhihu.com/p/60965109)



相关课程：

- [MIT 6.172: Performance Engineering of Software Systems (Fall 2018)](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-172-performance-engineering-of-software-systems-fall-2018)
  - [【MIT公开课】6.172 软件性能工程 · 2018年秋](https://www.bilibili.com/video/BV1wA411h7N7/) B站



